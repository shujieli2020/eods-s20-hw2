{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Due: Fri March. 27 @ 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and feature selection in both a regression and classification setting.\n",
    "\n",
    "The data we will be looking at are a small set of home sales data from as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "\n",
    "Please 'Restart and Run All' prior to submission.\n",
    "\n",
    "Out of 50 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Set up our environment with comman libraries and plotting.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, and matplotlib.pylab as plt\n",
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# Execute the matplotlib magic function to display plots inline\n",
    "____\n",
    "\n",
    "# Setting a seed for numpy random\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (3pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file house_sales_subset_normed.csv\n",
    "df = ____\n",
    "\n",
    "# Create a dataframe X which contains the first 5 columns:\n",
    "#    'SqFtTotLiving_x1000', 'SqFtLot_x1000', 'SqFtDriveway_x1000', 'Bathrooms', 'Bedrooms'\n",
    "X = ____\n",
    "\n",
    "# Create a series y_r which contains only the last column AdjSalePrice_x100000\n",
    "#    Note: the '_r' here is denote the different targets for regression and classification\n",
    "y_r = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (3pts) Create a held-aside set\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "____\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split \n",
    "#   Use random_state=42 for grading consistency\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = ____\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r to confirm our test set size.\n",
    "#    Only show 2 decimal places (eg: 0.11).\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (3pts) Create a Dummy Regressior for baseline comparison\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "____\n",
    "\n",
    "# Instantiate a dummy model using strategy=\"median\"\n",
    "dummy_r = ____\n",
    "\n",
    "# Train the dummy model on the training set created above\n",
    "#   In the output we should see the Dummy Regressor medel settings\n",
    "____\n",
    "\n",
    "# Calculate and print the training set R2 score of fit dummy model.\n",
    "dummy_r_training_r2 = ____\n",
    "print('dummy training set R2: {:.2f}'.format(dummy_r_training_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (2pts) Use 5-fold Cross Validation to get a set of negative-MSE scores\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross valication neg_mean_squared_error scores for the Dummy model on the training set.\n",
    "#    Note that most sklearn models require a scoring function where larger is better (eg.for gradient ascent)\n",
    "#    This is why cross_val_score uses 'neg_mean_squared_error' instead of 'mean_squared_error'.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (4pts) Write a function that takes in a set of negative-MSE scores \n",
    "#     and returns a tuple of \"positive mean RMSE\" and \"2*standard deviation\"\n",
    "\n",
    "def negmse_to_rmse(negmse_cvscores):\n",
    "    \n",
    "     # Flip the cv scores from negative to positive\n",
    "    mse_cvscores = ____\n",
    "\n",
    "    # Transform the cv scores from MSE to RMSE\n",
    "    rmse_cvscores = ____\n",
    "\n",
    "    # Calculate the mean RMSE over rmse_cvscores\n",
    "    rmse_mean = ____\n",
    "\n",
    "    # Calculate 2 standard deviations of rmse_cvscores\n",
    "    rmse_2std = ____\n",
    "    \n",
    "    return(rmse_mean,rmse_2std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (2pts) Use our negmse_to_rmse function to calculate mean-RMSE \n",
    "#     and standard deviations for the dummy model.\n",
    "\n",
    "# Pass dummy_r_negmse_cvscores to our function \n",
    "#   and capture the output as dummy_r_rmse and dummy_r_rmse_2std\n",
    "____ = ____\n",
    "\n",
    "# Print out the mean RMSE and 2 standard variations for the dummy model\n",
    "print('dummy mean cv RMSE: {:.2f} +- {:.2f}'.format(dummy_r_rmse,dummy_r_rmse_2std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. (4pts) Import the Linear Regression model and calculate average RMSE using 5-fold Cross Validation\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "____\n",
    "\n",
    "# Generate 5-fold cv neg_mean_squared_error scores \n",
    "#   for the LinearRegression model with default settings\n",
    "#   on the training set.\n",
    "lr_negmse_cvscores = ____\n",
    "\n",
    "# Use the function we wrote above to get mean RMSE and 2 standard deviations scores for LinearRegression.\n",
    "lr_rmse,lr_rmse_2std = ____\n",
    "\n",
    "# Print out the mean RMSE and 2 standard variations for LinearRegression\n",
    "print('lr mean cv RMSE: {:.2f} +- {:.2f}'.format(lr_rmse,lr_rmse_2std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (4pts) Plot the residuals of a Linear Regression model\n",
    "\n",
    "# Instantiate and retrain a linear regression model on the entire training set.\n",
    "lr = ____\n",
    "\n",
    "# Generate predictions y_pred, again using the training set.\n",
    "y_pred = ____\n",
    "\n",
    "# Calculate residuals\n",
    "#    Recall: residual = y - y_pred\n",
    "residuals = ____\n",
    "\n",
    "# Plot predictions (x-axis) vs residuals (y-axis) using ax.scatter()\n",
    "#    In scatter set alpha=0.2 to make the markers somewhat transparent.\n",
    "#    Set axis/label names appropriately ('y_pred' and 'residuals')\n",
    "# The residuals should appear fairly normal around 0 across the range of y_pred\n",
    "____\n",
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (3pts) Evaluate performance of our LinearRegression model using test\n",
    "\n",
    "# Import mean_squared_error from sklearn\n",
    "____\n",
    "\n",
    "# Retrain our LinearRegression model lr on the entire training set\n",
    "____\n",
    "\n",
    "# Calculate RMSE on the test set using the trained model\n",
    "test_rmse = ____\n",
    "\n",
    "print('test RMSE : {:.2f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a model to classify low vs. high adjusted sales price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a binary target by thresholding at the median of our AdjSalePrice\n",
    "#  High = 1, Low = 0\n",
    "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create a Held-Aside Aet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. (1pts) Create a training and held aside set\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split with random_state=42\n",
    "#    Use the new y_c target and the same X we used for regression\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (1pts) Instead of creating and training a Dummy Classifier, \n",
    "#    let's calculate accuracy if we just predict 1 for all training set items.\n",
    "\n",
    "# Compare all y_train_c to a prediction of 1 and calculate the proportion correct.\n",
    "baseline_acc = ____\n",
    "\n",
    "print('baseline accuracy: {:.2f}'.format(baseline_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3 Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. (4pts) Import, train and calculate 5-fold cv accuracy for a LogisticRegression model on the training set\n",
    "\n",
    "# Import LogisticRegression model from sklearn\n",
    "____\n",
    "\n",
    "# Get 5 fold cross-validation accuracy scores for a logistic regression model\n",
    "#   using default settings, on the training set\n",
    "#   Note: when instantianting, use solver='lbfgs' to remove warnings\n",
    "logr_cvscores = ____\n",
    "\n",
    "# Calculate mean cv accuracy\n",
    "logr_acc = ____\n",
    "\n",
    "# Calculate 2 standard deviations for the cv scores\n",
    "logr_acc_2std = ____\n",
    "\n",
    "print('logr mean cv accuracy: {:.2f} +- {:.2f}'.format(logr_acc,logr_acc_2std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 RandomForests and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. (5pts) Generate a validation curve over different tree depths in a Random Forest\n",
    "\n",
    "# Import the RandomForestClassifier from sklearn.ensemble\n",
    "____\n",
    "\n",
    "# Import the validation_curve function from sklearn.model_selection\n",
    "____\n",
    "\n",
    "# In the RandomForestClassifier model, the depth of trees is set via max_depth\n",
    "# Here we'll try the depths 3,5,10,20,30\n",
    "depths = [3,5,10,20,30]\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at these different depths using validation_curve\n",
    "#   Use a RandomForestClassifier() instance with default values\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use accuracy as the scoring metric\n",
    "train_scores,test_scores = ____\n",
    "\n",
    "# train_scores and test_scores contain a matrix of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean across folds (columns) and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = ____\n",
    "mean_test_scores = ____\n",
    "\n",
    "# There should be five numbers in each list, each value between 0 and 1\n",
    "print(mean_train_scores)\n",
    "print(mean_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. (4pts) Plot the validation curve\n",
    "\n",
    "# Plot mean_train_scores and mean_test_scores on the same plot\n",
    "#    use depths for the x values in each line\n",
    "#    add a label to each line\n",
    "#    add a legend\n",
    "#    add a meaningful xlabel and ylabel\n",
    "#    add a meaningful title\n",
    "____ # Note: use as many lines as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 RandomForests and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. (4pts) Perform 5-fold cross validated grid search over the number of trees and tree depth.\n",
    "\n",
    "# Import GridSearchCV\n",
    "____\n",
    "\n",
    "# Create the grid of parameters to test\n",
    "#   The parameter settings to try are n_estimators = [10,50,100,200], max_depth = [3,5,10,20,30]\n",
    "params = ____\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   using 3-folds (for speed), the RandomForestClassifier and default scoring.\n",
    "#   Make sure refit=True (default) so the model is retrained on the entire training set.\n",
    "gscv_rf = ____\n",
    "\n",
    "# Print out the best mean accuracy found and the best parameter setting found\n",
    "print('rf best accuracy: {:.3f}'.format(____))\n",
    "print('rf best params  : {}'.format(____))\n",
    "\n",
    "# (to think about, don't need to answer)\n",
    "#  Does this match what we might have guessed our max_depth should be from the validation plot above?\n",
    "#  Why might it not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. (1pts) Evaluate our trained RandomForest model on the test set\n",
    "\n",
    "# Calculate accuracy on the held aside test set using the random forest model in gscv_rf.\n",
    "#   Note that we don't need to retrain on the full X_train_c,y_train_c as we used refit=True\n",
    "test_acc = ____\n",
    "\n",
    "print('test acc : {:.2f}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s20",
   "language": "python",
   "name": "eods-s20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
